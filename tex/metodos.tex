\chapter{Materiais e métodos} \label{metodos}
O percurso metodológico desenvolvido neste trabalho é descrito nas seções seguintes deste capítulo. Como principal método, adotou-se um modelo clássico de descoberta de conhecimento em bases de dados, a partir do qual todas as as etapas da pesquisa foram deenvolvidas.
\section{Caracterização da pesquisa}

Segundo \citeonline{marconi2003fundamentos}, a pesquisa é um procedimento
formal, com método de pensamento reflexivo, que requer um tratamento científico
e que se constitui no caminho para conhecer a realidade ou para descobrir
verdades parciais. A pesquisa é um procedimento sistemático e crítico,  que
permite descobrir novos fatos, relações ou leis acerca de qualquer campo do
conhecimento.

Uma pesquisa pode ser caracterizada segundo os seguintes critérios
\cite{gil2008metodos}:
\begin{enumerate}[label=\alph*)]
  \item Quanto à natureza: básica ou aplicada;
  \item Quanto aos objetivos: exploratória, descritiva ou explicativa;
  \item Quanto à abordagem: qualitativa ou quantitativa;
  \item Quanto aos procedimentos: documental, bibliográfica, experimental,
  levantamento, estudo de caso, entre outros.
\end{enumerate}

Este trabalho pode ser classificado como de natureza aplicada, já que será
adotada uma metodologia para busca de conhecimentos em bancos de dados e métodos
de classificação para prever a evasão de cursos EAD.

Em relação aos objetivos, podemos classificar este trabalho como pesquisa
exploratória e descritiva. Tendo como base \citeonline{gil2002elaborar}, a
pesquisa exploratória busca ampliar o conhecimento sobre o problema, procurando
torná-lo mais explícito ou a construção de hipóteses, tendo como objetivo
central o aperfeiçoamento de ideias ou a revelação de intuições. E a pesquisa
descritiva objetiva descrever características de determinado fenômeno ou
população. Este trabalho utiliza uma metodologia de exploração de conhecimento
para tentar prever um comportamento em um conjunto de uma população.

Quanto à abordagem, este trabalho é classificado como quantitativo, em razão da
utilização de algorítmos de DM, a partir dos quais serão extraídas as
características dos estudantes de EAD e aplicados algoritmos de classificação
que farão a devida categorização.

No quesito procedimentos, classificamos este trabalho como pesquisa
experimental. De acordo com \citeonline{gil2002elaborar}, a pesquisa
experimental consiste em determinar um objeto de estudo, selecionar as variáveis
que seriam capazes de influenciá-lo, definir as formas de controle e de
observação dos efeitos que a variável produz no objeto.

No caso deste trabalho, o objeto de estudo é a evasão na EAD da UNIVASF e as
variáveis foram definidas com base na TDT.

\section{Método}

Para tratamento e preparação dos dados para os diferentes algoritmos de
classificação que serão avaliados, foi utilizado KDD como descrito por
\citeonline{tan2009introduccao} e ilustrado na Figura \ref{reducedKdd}.

\imagem{.70}{reduced_kdd}{\label{reducedKdd}Fluxo básico do processo KDD.}{\citeonline{tan2009introduccao}}

As subseções seguintes descrevem como o processo KDD foi aplicado neste
trabalho.

\subsection{Entrada de Dados}

A fase de entrada de dados foi desenvolvida, baseando-se no trabalho de
\citeonline{ramos2016abordagem}, coletando as variáveis mais relevantes que
poderiam representar cada um dos três construtos da TDT. Os dados das quais
foram retiradas as variáveis estão armazenados nas bases de dados do Sistema de
Gestão de Aprendizado Moodle\footnote{\url{https://moodle.org/} Acesso em: 06 de
mar. 2019}, atualmente, em uso pelos cursos de graduação oferecidos na
modalidade EAD pela UNIVASF. Os dados foram cedidos pela Secretaria de Educaçao a Distância
(SEAD) da UNIVASF, por meio da Secretaria de Tecnologia da Informação (STI), responsável pelo
suporte e manutenção das plataformas de EAD na instituição. Os dados foram então armazenados 
em um computador pessoal utilizando o Sistema de Gerenciamento de Banco de Dados (SGBD) MySQL.

O MySQL\footnote{\url{https://www.mysql.com/} Acesso em: 06 de mar. 2019} é o SGBD
mais popular no mundo. Provê performance, confiabilidade e facilidade de uso,
MySQL vem liderando a escolha de aplicações \textit{web}, usado por grandes
empresas na internet como: Facebook, Twitter, YouTube, Yahoo! e muitas outras.

O MySQL é utiliza Linguagem de Busca Estruturada (SQL, do inglês,
\textit{Structured Query Language}). Entre as suas vantagens podemos
listar: portabilidade, compatibilidade, excelente desempenho e estabilidade,
facilidade de manuseio e é um \textit{software} livre sob a licença GPL.

O Moodle é uma plataforma de ensino projetada para oferecer a educadores,
administradores e estudantes, com uma sistema integrado, simple e robusto, a
criação de ambientes de aprendizado personalizados. É apoiado por uma rede de
mais de 80 empresas ao redor do mundo.

O banco de dados Moodle é grande e complexo, retendo informações sobre os
diversos componentes de uma sala de aula virtual como \textit{chats},
questionários \textit{online} e fóruns de discussão, além de manter um registro de
todas as ações do usuário nos seus componentes.

A depender da versão do Moodle, a quantidade de tabelas na base de dados pode
variar significativamente. A versão utilizada neste trabalho possuía cerca de
430 tabelas. O Quadro \ref{moodleTableReferences} apresenta as tabelas
essenciais para a coleta dos dados utilizados neste trabalho.

\begin{quadro}[!htb]
  \centering
  \caption{Descrição das principais tabelas do BD Moodle, onde foram coletados dados desse trabalho.}
  \label{moodleTableReferences}
  \begin{tabular}{|l|l|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Tabela}} & \multicolumn{1}{c|}{\textbf{Descrição}} \\ \hline
    \textit{mdl\_assign} & \begin{tabular}[c]{@{}l@{}}Guarda informações sobre as atividades avaliativas\\ relacionadas com a produção de material pelos alunos em\\ cada disciplina.\end{tabular} \\ \hline
    \textit{mdl\_context} & \begin{tabular}[c]{@{}l@{}}Registra os níveis (contextos) de acesso de cada usuário, de\\ acordo com o seu perfil.\end{tabular} \\ \hline
    \textit{mdl\_course} & \begin{tabular}[c]{@{}l@{}}Tabela principal dos cursos, onde as disciplinas de cada curso\\ são registradas e configuradas.\end{tabular} \\ \hline
    \textit{mdl\_course\_categories} & \begin{tabular}[c]{@{}l@{}}Tabela auxiliar da \textit{mdl\_course}, onde são criadas as categorias\\ que podem representar cursos distintos (Biologia, Pedagogia\\ entre outros)\end{tabular} \\ \hline
    \textit{mdl\_forum} & \begin{tabular}[c]{@{}l@{}}Possui informações gerais de cada fórum criado nas\\ disciplinas.\end{tabular} \\ \hline
    \textit{mdl\_forum\_discussions} & Registra os tópicos criados em cada um dos fóruns. \\ \hline
    \textit{mdl\_forum\_posts} & \begin{tabular}[c]{@{}l@{}}Guarda as postagens dos alunos que são associadas aos\\ respectivos fóruns/tópicos.\end{tabular} \\ \hline
    \textit{mdl\_log} & \begin{tabular}[c]{@{}l@{}}Registra todas as ações dos usuários no ambiente. É a tabela\\ com maior número de registros.\end{tabular} \\ \hline
    \textit{mdl\_message\_read} & \begin{tabular}[c]{@{}l@{}}Armazena as mensagens que foram lidas pelos destinatários,\\ assim como o emissor e o receptor.\end{tabular} \\ \hline
    \textit{mdl\_role\_assignments} & \begin{tabular}[c]{@{}l@{}}Registros da atribuição de funções do usuário em contextos\\ diferentes.\end{tabular} \\ \hline
    \textit{mdl\_user} & Cadastro geral de usuários. \\ \hline
  \end{tabular}
  \Ididthis
\end{quadro}

Foram selecionados dois cursos dos quais foram extraídos os dados. O curso de
Bacharelado em Administração Pública com início no período letivo 2013.2 e
termino no período letivo 2017.1, contando com 285 estudantes e 41 disciplinas.
E o curso de Licenciatura em Pedagogia que ocorreu entre os períodos letivos de
2014.2 e 2018.1, com 160 estudantes e 39 disciplinas. A Tabela
\ref{courseInfoTable} apresenta um resumo dessas informações.

\begin{table}[!htb]
  \centering
  \caption{Resumo das informações dos cursos selecionados}
  \label{courseInfoTable}
  \begin{tabular}{@{}lrrrr@{}}
    \toprule
    \multicolumn{1}{c}{\textbf{Curso}} & \multicolumn{1}{c}{\textbf{Alunos}} & \multicolumn{1}{c}{\textbf{Disciplinas}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Período \\ Inicial\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Período \\ Final\end{tabular}}} \\ \midrule
    \begin{tabular}[c]{@{}l@{}}Bacharelado em \\ Administração Pública\end{tabular} & 285 & 41 & 2013.2 & 2017.1 \\ \midrule
    Licenciatura em Pedagogia & 160 & 39 & 2014.2 & 2018.1 \\ \bottomrule
  \end{tabular}
  \Ididthis
\end{table}

\subsection{Pré-processamento}

Devido ao grande volume de dados foram elaborados \textit{scripts} em SQL que
geram tabelas auxiliares apenas com dados dos das disciplinas contidas e alunos
matrículados nos cursos selecionados para este trabalho. Essas tabelas serão
apresentadas no capítulo de resultados.

As variáveis utilizadas neste trabalho foram baseadas na pesquisa de
\citeonline{ramos2016abordagem}, que também extraiu dados de uma instância do
Moodle. No entanto, ao invés de utilizar todas as variáveis, foram utilizadas
apenas as resultantes da etapa de seleção de variáveis realizada por Ramos em
sua tese de doutorado. Essas variáveis também serão descritas no capítulo de
resultados.

Foram elaborados \textit{scripts} SQL que, a partir das tabelas mencionadas
nos Quadros \ref{moodleTableReferences} e \ref{reducedDataTables}, foram construídas
tabelas com os dados brutos, onde cada linha gerada representa um aluno em uma
disciplina e as variáveis mapeadas para os construtos da TDT. As tabelas geradas
serviram como base para as etapas seguintes do processo KDD.

Para que as variáveis que dependiam de períodos de tempo fossem coletadas
corretamente, foi necessário inserir a data final de disciplinas que não
possuíam esse campo em suas linhas da tabela \textit{mdl\_course}. Nesses casos foi
inserida a data de fechamento do semestre. A data de início de algumas
disciplinas também teve que ser corrigida, pois, elas foram criadas nos
primeiros períodos, mas ocorreram posteriormente.

Foram necessárias várias iterações de ajustes nos \textit{scripts} e conferência
dos resultados antes de avançar para a próxima fase, como já havia sido
previsto, esta foi a etapa que consumiu a maior parcela do tempo de elaboração
desse trabalho. A conferência dos dados se deu a partir de acessos com perfil de professor
no Moodle, com acesso a várias disciplinas, onde eram feitas as contagem de eventos realcionados
às variáveis coletadas.

As tabelas geradas foram convertidas para planilhas eletrônicas para facilitar o
processo de filtragem e remoção de erros de implementação ou de configurações
feitas pelos gestores dos cursos. Foram removidos professores cadastrados como
alunos, disciplinas ofertadas para alunos repetentes e disciplinas ofertadas
fora do período (já que essas disciplinas poderiam enviesar os algoritmos de
classificação). Também foram eliminadas colunas que poderiam ser utilizadas para
identificar os alunos, com o objetivo de anonimizar os dados.

Disciplinas como Estágio Supervisionado, Trabalho de Conclusão de Curso entre outras,
também foram eliminadas, pois não seguem a mesma estrutura de disciplinas tradicionais,
podendo também causar vieses nos algoritmos.

Todos os \textit{scripts} gerados nessa etapa estão disponíveis no Anexo
\ref{anex:anexo1}

\subsection{Mineração de dados}

A análise exploratória dos dados foi realizada utilizando a
linguagem de programação Python, na distribuição Anaconda.

Python\footnote{\url{https://www.python.org/} Acesso em: 06 de mar. 2019} é uma
linguagem de programação de código aberto classificada como linguagem de alto
nível de abstração. Considerada de fácil manuseio mesmo por usuários iniciantes.
É mantida e desenvolvida pela Python Software Foundation

Graças a sua enorme comunidade, existem diversos pacotes e bibliotecas
desenvolvidas em Python para as mais variadas tarefas, desde servidores HTTP,
desenvolvimento de aplicações desktop até mineração de dados, inteligência
artificial e estatística.

A distribuição de código aberto
Anaconda\footnote{\url{https://www.anaconda.com/} Acesso em: 06 de mar. 2019}  é
uma maneira fácil de realizar tarefas de mineração de dados e aprendizado de
máquina em ambientes Linux, Windows ou Mac OS X. Anaconda é um gerenciador de
pacotes e ambientes e uma distribuição Python especializada em data science com
mais de 1500 pacotes de código aberto.

O ambiente de desenvolvimento selecionado foi o Jupyter Notebook, \footnote{\url{https://jupyter.org/} Acesso em: 06 de mar. 2019}
que é uma aplicação \textit{web} de código aberto que permite a criação e
compartilhamento de documentos que contém código em tempo de execução, equações,
visualizações e textos narrativos. Funciona como uma IDE (do inglês,
\textit{Integrated Development Environment}) e foi desenvolvido para tarefas de
limpeza e transformação de dados, simulações numéricas, modelagem estatística,
visualização de dados, aprendizado de máquina e mais.

Jupyter Notebook suporta mais de 40 linguagens de programação incluindo Python e
já vem pré configurado na distribuição Anaconda.

As planilhas foram carregadas no ambiente utilizando a Python Data Analysis
Library (pandas) em estruturas de dados denominadas \textit{dataframes}.

O Python Data Analysis Library\footnote{\url{https://pandas.pydata.org/} Acesso
em: 06 de mar. 2019}, ou simplesmente pandas, é uma biblioteca de código aberto
sob a licença BSD que provê estruturas de dados e ferramentas de análise de
dados de alta performance e fácil uso para a linguagem de programação Python.
Pandas proporciona estruturas de dados rápidas, flexíveis e expressivas
desenvolvidas para uso com dados relacionais ou etiquetados.

Foram analisadas as variáveis dos alunos do último período, após essa analise,
percebeu-se que nenhum aluno que estava listado havia evadido. Todas as
ocorrências desses alunos foram marcadas como não evadidos.

Percebeu-se que os administradores dos cursos removeram os alunos que evadiram
do quarto para o quinto semestre, então, foi necessário recolocar esses alunos
nas disciplinas que aconteceram após o quarto período. Todos os alunos que
tiveram de ser adicionados novamente foram marcados como evadidos.

Os \textit{dataframes} de cada curso foram divididos em dois conjuntos de dados,
conjunto de teste e conjunto de treino. Para tal, foi utilizada a função
\textit{train\_test\_split} da bilbioteca pandas. Essa função garante que os
dados sejam divididos de forma aleatória, o que mantém a mesma distribuição de
variáveis entre os conjuntos.

Cada par de conjunto de dados passou pelas seguintes etapas para cada algoritmo de
classificação.

1 - Treinamento: utilizando o conjunto de treinamento e por meio das funções e
classes disponibilizados pela biblioteca pandas, os algoritmos de classificação
são treinados ou ``aprendem'' os padrões dos dados.

Os algoritmos de classificação selecionados (KNN, Árvore de Decisão e Regressão
Logística) são disponibilizados pela biblioteca de ML em Python Scikit-learn.

Scikit-learn\footnote{\url{https://scikit-learn.org/} Acesso em: 06 de mar.
2019} é um módulo Python para aprendizado de máquina de código aberto sob a
licença BSD. Além das principais tarefas de mineração, como: classificação,
regressão e clusterização a biblioteca proporciona as visualizações mais básicas
para análise exploratória.

2 - Avaliação: utilizando o modelo resultante da etapa de treinamento e o conjunto
de teste avaliamos o classificador segundo as seguintes métricas: acurácia,
precisão, sensibilidade, especificidade.

3 - Importância de variáveis: de posse do modelo treinado, avaliamos quais variáveis
tiveram mais influência na performance do modelo através da classe
\textit{SelectFromModel} da biblioteca \textit{feature\_selection} no
scikit-learn.

\subsection{Pós-processamento}

Na última etapa, pós-processamento, foram avaliados e interpretados os padrões
extraídos na etapa de mineração, ocorreram retornos a etapa anterior para mais
iterações.

Os resultados desse processo serão detalhados no capítulo \ref{resultados}.
