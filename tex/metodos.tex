\chapter{Materiais e métodos}

\section{Caracterização da pesquisa}

Segundo \citeonline{marconi2003fundamentos}, a pesquisa é um procedimento
formal, com método de pensamento reflexivo, que requer um tratamento científico
e que se constitui no caminho para conhecer a realidade ou para descobrir
verdades parciais. A pesquisa é um procedimento sistemático e crítico,  que
permite descobrir novos fatos, relações ou leis acerca de qualquer campo do
conhecimento.

Uma pesquisa pode ser caracterizada segundo os seguintes critérios
\cite{gil2008metodos}:
\begin{enumerate}[label=\alph*)]
  \item Quanto à natureza: básica ou aplicada;
  \item Quanto aos objetivos: exploratória, descritiva ou explicativa;
  \item Quanto à abordagem: qualitativa ou quantitativa;
  \item Quanto aos procedimentos: documental, bibliográfica, experimental,
  levantamento, estudo de caso, entre outros.
\end{enumerate}

Este trabalho pode ser classificado como de natureza aplicada, já que será
aplicada uma metodologia de busca de conhecimentos em bancos de dados e métodos
de classificação para prever a evasão de cursos EAD.

Em relação aos objetivos podemos classificar este trabalho como pesquisa
exploratória e descritiva. Tendo como base \citeonline{gil2002elaborar}, a
pesquisa exploratória busca ampliar o conhecimento sobre o problema, procurando
torná-lo mais explícito ou a construção de hipóteses, tendo como objetivo
central o aperfeiçoamento de ideias ou a revelação de intuições. E a pesquisa
descritiva objetiva descrever características de determinado fenômeno ou
população. Este trabalho utiliza uma metodologia de exploração de conhecimento
para tentar prever um comportamento em um conjunto de uma população.

Quanto à abordagem, este trabalho é classificado como quantitativo, em razão da
utilização de abordagens algorítmicas de Mineração de Dados, a partir das quais
serão extraídas as características dos estudantes de EAD e aplicadas modelos de
classificação que farão a devida categorização.

No quesito procedimentos classificamos este trabalho como pesquisa experimental.
De acordo com \citeonline{gil2002elaborar}, a pesquisa experimental consiste em
determinar um objeto de estudo, selecionar as variáveis que seriam capazes de
influenciá-lo, definir as formas de controle e de observação dos efeitos  qua
variável produz no objeto.

No caso deste trabalho, o objeto de estudo é a evasão na EAD da UNIVASF e as
variáveis foram definidas pela TDT.

\section{Método}

Para tratamento e preparação dos dados para os diferentes modelos de
classificação que serão avaliados, será utilizado o processo de Descobrimento de
Conhecimento em Banco de Dados (do inglês, \textit{Knowledge Discovery in
Databases}, KDD) como descrito por \citeonline{tan2009introduccao} e ilustrado
na Figura \ref{reducedKdd}. Este processo envolve uma série de passos com o
objetivo de transformar dados brutos em informações úteis.

\imagem{.70}{reduced_kdd}{\label{reducedKdd}Fluxo básico do processo KDD}{\citeonline{tan2009introduccao}}

A fase de entrada de dados será desenvolvida, baseado no trabalho de
\citeonline{ramos2016abordagem}, coletando as variáveis mais relevantes que
poderiam representar cada um dos três construtos da TDT. Os dados de onde serão
retiradas as variáveis estão armazenados nas bases de dados do Moodle,
atualmente em uso pelos cursos de graduação oferecidos pela UNIVASF na
modalidade EAD.

Na etapa de pré-processamento de dados ocorrem as transformações e adaptações
dos dados para os algoritmos de Mineração de Dados. Entre essas transformações
podemos citar: normalização, limpeza de valores faltantes, identificação de
outliers, entre outros. Esta etapa, geralmente, exige muito tempo e esforço. A
correta execução deste passo resultará em melhores resultados nas etapas
posteriores.

No contexto deste trabalho, utilizaremos ferramentas de análises exploratórias e
\textit{scripts} de buscas em bancos de dados para construção da base de dados a
ser utilizada na etapa posterior.

Em seguida, ocorre a etapa de mineração de dados, onde são buscados padrões de
interesse ou características que representem as tendências dos dados, entre os
métodos de busca de padrões podemos citar: clusterização, classificação,
regressão, entre outros.

Para este trabalho, utilizaremos os algoritmos de classificação a seguir: Árvore
de Decisão, KNN, e Regressão Logística. Nesta etapa, os parâmetros dos
algoritmos de classificação serão ajustados para que a performance dos mesmos
seja melhorada.

Na última etapa, pós-processamento, serão avaliados e interpretados os padrões
extraídos na etapa de mineração, podem ocorrer retornos a qualquer etapa
anterior para mais iterações. Esta etapa pode envolver a visualização dos
padrões e modelos gerados, ou visualização dos dados fornecidos. Neste passo, o
conhecimento descoberto será documentado para possível uso posterior, em uma
ferramenta de geração de relatórios ou de visualização, tipo dashboard.

\section{Materiais}

\subsection{Moodle}

O Moodle\footnote{\url{https://moodle.org/} Acesso em: 06 de mar. 2019} é uma
plataforma de ensino projetada para oferecer a educadores, administradores e
estudantes, com uma sistema integrado, simple e robusto, a criação de ambientes
de aprendizado personalizados. É financiado por uma rede de mais de 80 empresas
ao redor do mundo.

Moodle é um software de código aberto sob a licença GNU General Public License.
Qualquer pessoa pode adaptá-lo, estendê-lo ou modificá-lo, tanto para uso
comercial ou não-comercial, sem nenhum tipo taxa de licenciamento e se
beneficiando de sua eficiência e custo, flexibilidade e outras vantagens de usar
o Moodle.

\subsection{MySQL}

MySQL\footnote{\url{https://www.mysql.com/} Acesso em: 06 de mar. 2019} é a base
de dados mais popular no mundo. Provê performance, confiabilidade e facilidade
de uso, MySQL vem liderando a escolha de aplicações web, usado por grandes
empresas na internet como: Facebook, Twitter, YouTube, Yahoo! e muitas outras.

MySQL é sistema de gerenciamento de banco de dados (SGDB), baseado na linguagem
SQL (do inglês, Structured Query Language). Entre as vantagens suas vantagens
podemos listar: portabilidade, compatibilidade, excelente desempenho e
estabilidade, facilidade de manuseio e é um software livre sob a licença GPL.

\subsection{Python}

Python\footnote{\url{https://www.python.org/} Acesso em: 06 de mar. 2019} é uma
linguagem de programação de código aberto classificada como linguagem de alto
nível de abstração. Considerada de fácil manuseio mesmo por usuários iniciantes.
É mantida e desenvolvida pela Python Software Foundation

Graças a sua enorme comunidade, existem diversos pacotes e bibliotecas
desenvolvidas em Python para as mais variadas tarefas, desde servidores HTTP,
desenvolvimento de aplicações desktop até mineração de dados, inteligência
artificial e estatística.

\subsection{Anaconda Python Distribution}

A distribuição de código aberto
Anaconda\footnote{\url{https://www.anaconda.com/} Acesso em: 06 de mar. 2019}  é
uma maneira fácil de realizar tarefas de mineração de dados e aprendizado de
máquina em ambientes Linux, Windows ou Mac OS X. Anaconda é um gerenciador de
pacotes e ambientes e uma distribuição Python especializada em data science com
mais de 1500 pacotes de código aberto.

\subsection{Jupyter Notebook}

Jupyter Notebook\footnote{\url{https://jupyter.org/} Acesso em: 06 de mar. 2019}
é uma aplicação web de código aberto que permite a criação e compartilhamento de
documentos que contém código em tempo de execução, equações, visualizações e
textos narrativos. Funciona como uma IDE (do inglês, Integrated Development
Environment) e foi desenvolvido para tarefas de limpeza e transformação de
dados, simulações numéricas, modelagem estatística, visualização de dados,
aprendizado de máquina e mais.

Jupyter Notebook suporta mais de 40 linguagens de programação incluindo Python e
já vem pré configurado na distribuição Anaconda.

\subsection{Python Data Analysis Library}

Python Data Analysis Library\footnote{\url{https://pandas.pydata.org/} Acesso
em: 06 de mar. 2019}, ou simplesmente pandas, é uma biblioteca de código aberto
sob a licença BSD que provê estruturas de dados e ferramentas de análise de
dados de alta performance e fácil uso para a linguagem de programação Python.
Pandas proporciona estruturas de dados rápidas, flexíveis e expressivas
desenvolvidas para uso com dados relacionais ou etiquetados.

A biblioteca pandas já vem configurada para uso na distribuição Anaconda.

\subsection{Numpy}

NumPy\footnote{\url{http://www.numpy.org/} Acesso em: 06 de mar. 2019} é o
pacote fundamental para computação científica em Python. Contento, além de outra
funcionalidades, um poderoso vetor n-dimensional, funções de broadcast
sofisticadas, ferramentas de integração com códigos C/C++ e Fortran, ferramentas
de algebra linear, transformadas de Fourier e números aleatórios.

Além dos óbvios usos científicos, NumPy também pode ser usado como um invólucro
para dados genéricos. Tipos de dados arbitrários podem ser definidos, isso
permite que  seja integrado de forma rápida com uma miríade de bases de dados.

NumPy é uma biblioteca de código aberto sob a licença BSD e é presente na
distribuição Anaconda.

\subsection{Scikit-learn}

Scikit-learn\footnote{\url{https://scikit-learn.org/} Acesso em: 06 de mar.
2019} é um módulo Python para aprendizado de máquina de código aberto sob a
licença BSD. Além das principais tarefas de mineração, como: classificação,
regressão e clusterização a biblioteca proporciona as visualizações mais básicas
para análise exploratória. Scikit-learn é compatível com pandas e NumPy e pode
ser encontrado na distribuição Anaconda.
