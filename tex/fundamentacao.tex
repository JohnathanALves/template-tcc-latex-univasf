\chapter{Fundamentação Teórica}

A necessidade de apoiar o desenvolvimento da EAD tem feito surgir novas teorias,
métodos, abordagens de ensino e tratamento das informações, geradas nas diversas
tecnologias usadas nessa modalidade. Nas seções seguintes, serão abordadas as
principais temáticas envolvidas neste estudo, o que oferecerá as bases teóricas
necessárias para a fundamentação da pesquisa.

\section{Teoria da Distância Transacional}

Em 1972, Michael Grahame Moore propôs uma teoria pioneira para a EAD. Essa
teoria seria, posteriormente, denominada de Teoria da Distância Transacional
(TDT). Ao longo de mais de 40 anos, desde da proposição da TDT, o próprio autor
e outros pesquisadores trataram de atualizá-la, principalmente, em razão da
evolução tecnológica. Os textos originais do autor estão nas suas obras de 1973,
1993 e 2013 \cite{moore1973transational}. Todas as citações a este autor, neste
texto, sem o ano, referem-se à estas obras.

Em seus estudos, \citeauthoronline{moore1973transational} afirmou que na EAD não
existe apenas uma distância física entre professores e alunos, mas, também, uma
distância psicológica. Na TDT, as interações do estudante, com o professor, com
o conteúdo e com os estudantes, podem ser estudadas com base em construtos
elementares, sendo eles, a estrutura dos programas ou cursos, o diálogo entre
alunos e professores e o grau de autonomia do discente. De acordo com a TDT a
EAD tem a sua própria identidade e características pedagógicas distintivas. Como
outras teorias, a TDT pode ser usada no estabelecimento de uma heurística, para
a tomada de decisões em projetos de cursos EAD
\citeauthor{moore1973transational}.

\citeonline{dewey1960knowing} elaboraram o conceito de transação, que, conforme
foi exposto posteriormente por \citeonline{boyd1980redefining}, denota a
interação entre o ambiente, os indivíduos e os padrões de comportamento numa
dada situação. Uma transação, em EAD, é a interação entre professores e alunos
que estão espacialmente separados. Como foi definido por
\citeauthoronline{moore1973transational}, essa separação cria padrões especiais
de comportamento que afetam tanto o ensino quanto o aprendizado. Derivado da
separação, surge um espaço psicológico e comunicacional propício a
mal-entendidos nas interações instrutor-aluno. A esta separação é dado o nome de
Distância Transacional (DT).

Faz-se necessário lembrar que, segundo \citeauthoronline{moore1973transational}
a distância transacional não é um valor fixo ou dicotômico, na verdade, é um
valor relativo e contínuo. Além disso, essa distância é diferente para cada
estudante, mesmo entre os que compartilham o mesmo curso. Foi apontado por
\citeonline{rumble1986planning} que existe uma DT mesmo em cursos presenciais.
Com base nisso, pode-se dizer que a EAD é um subconjunto da educação e os
estudos realizados em EAD podem auxiliar a teoria e a prática da educação
tradicional. Porém, em uma situação classificada como EAD, a distância entre os
participantes --- professores e alunos --- é grande o suficiente para justificar
a investigação de técnicas próprias de ensino-aprendizagem.

Os procedimentos de ensino se dividem em dois grupos, e acontece também um
terceiro grupo de variáveis que descreve o comportamento dos alunos. A DT é uma
função desses três grupos de variáveis. Na TDT, estes grupos de variáveis
recebem o nome de Diálogo, Estrutura e Autonomia do Aluno
\citeauthor{moore1973transational}.

\subsection{Diálogo}

O diálogo foi originalmente definido por
\citeauthoronline{moore1973transational} como sendo interações focadas,
positivas e propositais entre o professor e os alunos. Ainda segundo Moore, o
diálogo ocorre entre professores e alunos quando alguém ensina e os demais
reagem. O diálogo deve ser direcionado para o aperfeiçoamento da compreensão por
parte do aluno.

``A extensão e natureza do diálogo são determinadas pela filosofia educacional
da instituição responsável pelo projeto do curso, pelas personalidades do
professor e do aluno, pelo tema do curso e por fatores ambientais.''
\cite[p.~438]{cabau2018teoria}.

\citeauthoronline{moore1973transational} cita meios de comunicação como um
importante fator ambiental na EAD, no entanto, relata ser importante que outras
variáveis sejam atendidas à medida que a EAD amadurece, as variáveis destacadas
por Moore foram: projeto de curso, seleção e treinamento de instrutores e o
estilo de aprendizagem dos alunos.

O diálogo é o mediador central da DT e referenciado como medida de aprendizado
ao passo que a DT seria uma medida de não-aprendizado. No entanto, já que o
diálogo não se limita apenas à interação professor-aluno, especialmente com os
avanços da EAD provendo novas formas de interações entre estudantes, diversos
pesquisadores vêm propondo a inclusão de interações entre alunos no conceito de
diálogo \cite{benson2009addressing,chen1999dimensions,huang2016understanding}.

\subsection{Estrutura do curso}

A estrutura do curso diz respeito aos elementos do projeto, bem como, divisão do
curso em unidades, objetivos, estratégias institucionais e métodos de avaliação.
A estrutura transmite a flexibilidade ou rigidez dos elementos do curso. É,
também, responsável pela facilitação ou não-facilitação do diálogo
\citeauthor{moore1973transational}.

Como o diálogo, a estrutura do curso é uma variável qualitativa, e a medida da
estrutura em um programa EAD é, normalmente, determinada pela natureza dos meios
de comunicação empregados, e também pela filosofia e personalidade dos
professores, pelas personalidades dos alunos e pelas restrições impostas pelas
instituições educacionais \citeauthor{moore1973transational}.

Embora Moore atribua como qualitativa o tipo de variável relacionada ao diálogo
e à estrutura, diversos estudos recentes mostraram que é possível quantificar e
mensurar esses componentes da TDT
\cite{zhang2003transactional,horzum2011developing,paul2015revisiting,
ramos2016abordagem}.

Em cursos gravados em fitas, discos, ou mesmo cursos televisionados a estrutura
é rígida e o diálogo não existe, pois não é possível reorganizar o conteúdo para
levar em consideração as interações de um aluno. Em contrapartida cursos por
teleconferências, permitem ampla variedade de respostas alternativas do
instrutor às perguntas dos participantes. Um curso altamente estruturado não
possibilita o diálogo professor-aluno, consequentemente, a DT entre alunos e
professores aumenta. No entanto, o contrário não pode ser generalizado. ``\ldots
a extensão do diálogo e a flexibilidade da estrutura variam de programa para
programa. É essa variação que dá a um programa maior ou menor distância
transacional que outro'' \citeauthor{moore1973transational}.

Em um programa com pequena DT os alunos recebem instruções e orientações por
meio do diálogo com o instrutor, nesse caso é possível ter uma estrutura aberta,
que dê respaldo para tais interações. Em programas com maior DT é necessário uma
estrutura robusta, materiais didáticos que forneçam todas as orientações,
instruções e aconselhamentos que o instrutor puder prever, mas sem a
possibilidade de alterações por meio de diálogo aluno-professor
\citeauthor{moore1973transational}.

Temos então que, em programas com maior DT, os alunos precisam se
responsabilizar em escolher quais atividades e avaliações serão feitas e quando
serão feitas. Mesmo que o curso seja bem estruturado, o estudante, na falta de
diálogo, decidirá quais atividades serão realizadas, quando, e qual a
importância de cada uma. Sendo assim, quanto maior a DT mais é exigido uma
autonomia do aluno \citeauthor{moore1973transational}.

\subsection{Autonomia do aluno}

No período do surgimento da TDT, na década de 1970, ela representava a fusão de
duas tradições pedagógicas que pareciam contraditórias. Uma, a tradição
humanística, que valorizava o diálogo aberto, não-estruturado e interpessoal,
tanto na educação quanto no aconselhamento. A outra, a tradição behaviorista,
que valorizava o projeto sistemático da instrução, baseado em objetivos
comportamentais com o máximo de controle do processo de aprendizagem por parte
do professor. No início dos anos 1970, a EAD era dominada pela tradição
behaviorista, tanto que, o título do primeiro trabalho sobre a TDT de
\citeonline{moore1972learner} foi: ``A autonomia do aluno --- a segunda dimensão
da aprendizagem independente''. Nesse trabalho Moore afirmou que: ``educadores
por correspondência limitavam o potencial do seu método ao negligenciar a
habilidade dos alunos em compartilharem a responsabilidade por seus próprios
processos de aprendizagem'' \citeauthor{moore1973transational}.

O termo ``autonomia do aluno'' foi escolhido para descrever os padrões de
comportamento de alunos que usavam materiais didáticos e programas de ensino
para atingir seus próprios objetivos, à sua maneira e sob seu próprio controle
\citeauthor{moore1973transational}.

Autonomia do aluno  se refere a capacidade de se auto-direcionar.
\citeauthoronline{moore1973transational} definiu o estudante autônomo ideal como
``a pessoa emocionalmente independente de um professor'' e quem ``tem capacidade
de abordar o assunto estudado diretamente sem a ajuda de um instrutor''.
Diferente da estrutura do curso e do diálogo, é um fator que depende apenas do
aluno. Um aprendiz pouco autônomo pode precisar de um direcionamento maior e uma
estrutura mais rígida \cite{huang2016understanding}.

\section{Evasão de alunos na EAD}

O censo realizado pela Associação Brasileira de Educação a Distância
(ABED), com dados de 2016, consultou 340 instituições em todo o país, formadoras
e fornecedoras de de produtos e serviços para EAD \cite{abed2016ead}.

De acordo com o Censo EAD.BR 2016, as taxas de evasão informadas pelos
respondentes recaíram, principalmente, entre 11\% e 25\%. O censo, também,
revelou que, entre os respondentes, cursos semipresenciais tem taxa de evasão
menor que cursos totalmente a distância. A Tabela \ref{tableEvasionTax1} compara
os índices dos censos realizados pela ABED entre 2014 e 2017
\cite{abed2013ead,abed2014ead,abed2015ead,abed2016ead}.

\begin{table}[!htb]
  \centering
  \caption{\label{tableEvasionTax1} Taxas de evasão ao longo dos anos segundo o censo realizado pela ABED}
  \begin{tabular}{@{}lllll@{}}
    \toprule
    \multicolumn{1}{c}{\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Taxas de evasão \\ declaradas\end{tabular}}}} & \multicolumn{4}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Percentuais de instituições\\ declarantes, por faixa\end{tabular}}} \\ \cmidrule(l){2-5}
    \multicolumn{1}{c}{} & \textbf{2013} & \textbf{2014} & \textbf{2015} & \textbf{2016} \\ \midrule
    Até 25\% & 65\% & 50\% & 53\% & 58\% \\
    Entre 26 e 50\% & 24\% & 38\% & 40\% & 19\% \\
    Acima de 50\% & 2\% & 2\% & 7\% & 1\% \\
    Não declararam & 9\% & 10\% & - & 22\% \\ \bottomrule
  \end{tabular}
  \Otherguydidthis{abed2013ead,abed2014ead,abed2015ead,abed2016ead}
\end{table}

Entre os motivos para a evasão investigados e declarados no censo, questões
financeiras e falta de tempo foram os citados como os que geram maior evasão.
Houve uma parcela considerável de respondentes que acredita que a evasão não é
um problema em cursos totalmente a distância, pois os participantes podem sempre
retornar.

Em cursos livres, o motivo mais citado foi a falta de tempo, e, também, grande
parte dos respondentes acredita que os alunos desses cursos sempre podem
retornar.

O Censo EAD.BR 2016 apontou que cursos presenciais, semipresenciais e
corporativos possuem mecanismos que vão além do conteúdo e da interação online
com professores para manter seus alunos engajados. Já os cursos totalmente a
distância e cursos livres não corporativos dependem apenas da experiência do
aluno com o conteúdo e com seus professores e tutores.

A Tabela \ref{tableEvasionTax2} apresenta dados dos indicadores da evasão, em
cursos superiores a distância, segundo o Mapa do Ensino Superior no Brasil
Edições 2015 e 2016, que foram publicados pelo Sindicato das Empresas
Mantenedoras do Ensino Superior (SEMESP) feito com base nos dados do INEP dos
anos 2013 e 2014.

\begin{table}[!htb]
  \centering
  \caption{\label{tableEvasionTax2} Taxas de evasão em cursos superiores presenciais e a distância}
  \begin{tabular}{@{}ccccc@{}}
    \toprule
    \multirow{2}{*}{\textbf{Ano}} & \multicolumn{2}{c}{\textbf{Cursos presenciais}} & \multicolumn{2}{c}{\textbf{Cursos a Distância}} \\ \cmidrule(l){2-5}
    & \textbf{IES públicas} & \textbf{IES privadas} & \textbf{IES públicas} & \textbf{IES privadas} \\ \midrule
    2013 & 17,8\% & 27,4\% & 25,6\% & 29,2\% \\
    2014 & 18,3\% & 27,9\% & 26,8\% & 32,5\% \\ \bottomrule
  \end{tabular}
  \legend{\textbf{Fonte:} \citeonline{semesp2015mapa,semesp2016mapa}}
\end{table}

Segundo o trabalho de \citeonline{paz2017identificando} a evasão em instituições
de ensino superior (IES) é um tema complexo na gestão universitária no Brasil.
Um grave problemas das universidades brasileiras é o aumento das taxas de evasão
escolar.

\citeonline{manhaes2012identificaccao} identificaram que a descoberta precoce de
grupos de estudantes com risco de evasão é condição importante para reduzir tal
problema, pois possibilita proporcionar algum tipo de atendimento personalizado
para a situação de cada aluno. Ainda segundo
\citeonline{manhaes2012identificaccao}, os processos de identificação desses
grupos à época eram manuais e sujeitos a falhas e dependiam, primordialmente, da
experiência do docente.

\section{Relação entre a distância transacional e a evasão em cursos a distância}

Pela sua definição, a Distância Transacional é um dos fatores que pode gerar
maior dificuldade no engajamento e na comunicação do estudante no ambiente de
aprendizagem \cite{goel2012transactional}. Além de
\citeauthoronline{moore1973transational}, outros autores afirmaram que quanto
maior for a DT, maior a possibilidade de ocorrência de problemas como atritos,
insatisfações e abandono de cursos
\cite{zhang2003transactional,steinman2007educational,horzum2011developing,
mbwesa2014transactional,paul2015revisiting}.

\citeonline{zhang2003transactional}, em sua tese de doutorado,
demonstrou a existência de uma correlação negativa entre a distância
transacional e o envolvimento dos alunos com a sua aprendizagem, assim como com
a sensação de satisfação e a intenção do aluno em persistir no seu curso
\textit{on-line}.

Para \citeonline{steinman2007educational}, as percepções dos alunos de cursos
\textit{on-line} podem ser negativas se eles experimentam grande DT com o
instrutor e com outros alunos, podendo ainda influenciar sua decisão de
permanecer ou abandonar o curso. Assim, uma vez que a DT afeta a satisfação e
retenção dos alunos, esse conceito é visto como um importante tópico de
discussão sobre evasão em cursos \textit{on-line}.

A obtenção dos construtos da DT pode refletir uma condição ou um estado de um
curso no tempo de sua execução, permitindo, por exemplo, que professores e
tutores notem um distanciamento exagerado de determinados alunos e consigam
intervir no sentido de prevenir ou reverter situações de evasão de alunos do
curso \cite{horzum2011developing}.

\section{Descoberta de Conhecimento}

De acordo com \citeonline{costa2012mineraccao} Mineração de Dados (DM, do
inglês, \textit{Data Mining}), pode ser interpretada como uma etapa de um
processo mais amplo denominado como Descoberta de Conhecimento em Bases de Dados
(KDD, do inglês, \textit{Knowledge Discovery in Databases}). No KDD são
identificadas duas grandes etapas: a de pré-processamento de dados, na qual os
dados são captados, tratados e organizados, e a de pós-processamento dos
resultados obtidos da etapa de mineração \cite{fayyad1996data}.

Para a obtenção de conhecimentos relevantes, no KDD, é necessário estabelecer
metas bem definidas. No estudo de \citeonline{fayyad1996data}, as metas são
definidas em função do objetivo na utilização da metodologia, sendo dois tipos
básicos de metas: verificação e descoberta. No caso de verificação, o sistema
está limitado a testar hipóteses definidas pelo usuário, enquanto que em
descoberta o sistema encontra novos padrões de forma autônoma. Quando a meta é
do tipo descoberta, em geral, o objetivo está relacionado com as seguintes
tarefas de mineração de dados: predição e descrição.

As tarefas preditivas buscam descobrir o valor de um determinado atributo com
base nos valores de outros atributos. O atributo a ser predito pode ser chamado
de variável preditiva, dependente ou alvo, já os atributos utilizados na
predição são chamados de variáveis preditoras, independentes ou explicativas.
Sendo generalista, a predição utiliza um conjunto de variáveis para predizer o
valor de outras \cite{fayyad1996data}.

Tarefas descritivas objetivam encontrar padrões --- correlações, tendências,
grupos, trajetórias e anomalias --- que representem os dados
\cite{fayyad1996data}.

Para realizar tarefas de predição e descrição são utilizados alguma das
seguintes tarefas e métodos de mineração de dados: classificação, regressão,
agrupamento, sumarização, modelagem de dependência e identificação de mudanças e
desvios.

Conforme \citeonline{tan2009introduccao}, DM é uma parte do KDD, um processo
geral de conversão de dados brutos em informações úteis, sendo este composto de
uma séries de passos de transformação, do pré-processamentos dos dados até o
pós-processamento dos resultados da mineração de dados. A Figura \ref{kddTan}
ilustra uma visão geral do KDD segundo Tan et al.

\imagem{0.85}{kdd_tan}{\label{kddTan} Processo de descoberta de conhecimento em bases de dados}{\citeonline{tan2009introduccao}}

Ainda de acordo com \citeonline{tan2009introduccao}, os dados de entrada podem
estar armazenados nos mais diversos formatos (tabelas eletrônicas, bases de
dados estruturadas, arquivos simples), e podem estar em um único repositório ou
distribuídos por diversas fontes. A etapa de pré-processamento é responsável por
transformar os dados brutos em dados apropriados para as análises seguintes.
Fusão de dados de múltiplas fontes, limpeza para remoção de ruídos, e seleção de
características relevantes à DM, são passos importantes realizados na etapa de
pré-processamento. Como existem diversas formas de se coletar e armazenar os
dados, o pré-processamento se torna, muitas vezes, a etapa mais demorada e
trabalhosa do KDD.

De acordo com \citeonline{tan2009introduccao}, o pós-processamento é a etapa do
KDD na qual os dados válidos e úteis gerados na etapa de mineração são
integrados a ferramentas de auxílio na tomada de decisões. Um exemplo de
pós-processamento é a visualização de dados, que permite por meio de gráficos,
auxiliar na interpretação de comportamentos e características dos dados. Também
podem ser utilizados testes estatísticos para eliminar resultados não legítimos
da mineração de dados.

\subsection{Mineração de Dados Educacionais}

Segundo \citeonline{costa2012mineraccao}, a área emergente de Mineração de Dados
Educacionais (EDM, do inglês, \textit{Educational Data Mining}) procura
desenvolver ou adaptar métodos e algoritmos de mineração existentes, de tal modo
que se prestem a compreender melhor os dados em contextos educacionais,
produzidos principalmente por estudantes e professores, considerando os
ambientes nos quais eles interagem, tais como AVAs, Sistemas Tutores
Inteligentes (STIs), entre outros.

Muitos métodos utilizados em EDM são, originalmente, da área de mineração de
dados. No entanto, no trabalho de \citeonline{baker2010data}, muitas vezes estes
métodos devem ser modificados, por se fazer necessário considerar a hierarquia
da informação. Existe também, falta de independência estatística nos tipos de
dados encontrados ao coletar informações em contextos educacionais. Logo,
diversos algoritmos e ferramentas utilizadas na área de DM não podem ser
aplicados para análise de dados educacionais sem sofrerem os devidos ajustes
\cite{baker2011mineraccao,costa2012mineraccao}.

A EDM pode ser descrita como a combinação de três áreas principais (Figura
\ref{edmAreasVenn}): ciência da computação, educação e estatística. As
interseções dessas três áreas forma subáreas próximas da EDM, como sendo
aanalíticas de aprendizagem (LA, do inglês, \textit{Learning Analytics}),
ambientes de aprendizado baseados em computador e aprendizado de máquina
\cite{romero2013data}.

\imagem{0.85}{areas_em_correlacao_com_EDM}{\label{edmAreasVenn} Principais áreas relacionadas com EDM}{\citeonline{romero2013data}}

\section{Aprendizagem Supervisionada}

O campo do Aprendizado de Máquina (ML, do inglês, \textit{Machine Learning})
fornece uma ampla área para cientistas explorarem modelos e algoritmos de
aprendizado que podem ajudar ``máquinas'' (computadores) a aprender sobre um
sistema com base em dados. Em outras palavras, o objetivo do ML é construir
sistemas inteligentes. Algoritmos de aprendizado são ferramentas de
reconhecimento de padrão. A seguir é apresentado, de uma forma geral, a
descrição de um problema de ML. Suponha que são dados um conjunto de dados e sua
respectiva resposta para um sistema. Então, o problema de ML pode ser definido
como ajustar um modelo entre eles, os dados e sua resposta, e como treinar e
validar o modelo para aprender as características do sistema por meio dos dados
\cite{suthaharan2016machine}.

A tarefa de Aprendizagem Supervisionada é a seguinte:

Dados um conjunto de treinamento de \(N\) exemplos de pares entrada/saída
\[ (x_1,y_1),(x_2,y_2)\ldots(x_n,y_n), \]
onde cada \(y_j\) foi gerado por uma função desconhecida \(y = f(x)\), descobrir
uma função \(h\) que aproxime a verdadeira função \(f\)
\cite{russell2011artificial}.

Na definição anterior, \(x\) e \(y\) podem ser qualquer valor, não
necessariamente numérico. A função \(h\) é uma hipótese. Aprender é procurar em
um espaço de hipóteses possíveis por uma que tenha alto desempenho, mesmo em
exemplos não contidos no conjunto de treinamento. Para mensurar a acurácia de
uma hipótese se utiliza um conjunto de teste, exemplos que são distintos do
conjunto de treinamento. É dito que uma hipótese generaliza bem se prediz
corretamente os valores \(y\) para exemplos novos \cite{russell2011artificial}.

Quando a saída \(y\) é uma em um conjunto finito de valores, o problema de
aprendizado é denominado classificação, e é chamado classificação booleana ou
classificação binária quando existem apenas dois valores
possíveis\cite{russell2011artificial}.

\subsection{Classificação}

De acordo com \citeonline{tan2009introduccao} a Classificação é a tarefa de
aprender uma função alvo \(f\) que mapeie cada conjunto de atributos \(x\) para
um dos rótulos de classes \(y\) pré-determinados. A função alvo também pode ser
chamada de modelo de classificação.

\begin{figure}[!htb]
  \centering
  \caption{\label{classification} Exemplo de classificação}
  \subcaptionbox{\label{classificationA}}{\includegraphics[scale=.80]{img/classificacao_a}}\qquad
  \subcaptionbox{\label{classificationB}}{\includegraphics[scale=.80]{img/classificacao_b}}
  \vspace{1.5em}
  \Otherguydidthis{suthaharan2016machine}
\end{figure}

Em problemas de classificação, assumimos que são disponibilizados dados
etiquetados (classes) para gerar regras que podem ajudar a atribuir uma etiqueta
a novos dados que não possuem classes. Nesse caso, podemos derivar uma regra
exata pela disponibilidade das classes. A Figura \ref{classification} ilustra um
exemplo com duas classes, etiquetadas com pontos brancos e pontos pretos, e uma
reta (Figura \ref{classificationB}) representado a regra que nos ajuda a
estabelecer uma classe para cada novo ponto \cite{suthaharan2016machine}.

\imagem{.7}{construcao_de_classificacao}{\label{classificationConstruction}
Abordagem geral para a construção de um modelo de classificação}
{\citeonline{tan2009introduccao}}

Em uma abordagem geral, para a construção de um modelo de classificação,
primeiro, um conjunto de treinamento consistindo de registros com rótulos de
classe conhecido é fornecido. O conjunto de treinamento é usado para construir
um modelo de classificação, que é então aplicado a um conjunto de testes,
constituído por registros com rótulos desconhecidos para o modelo. A Figura
\ref{classificationConstruction} ilustra essa abordagem geral
\cite{tan2009introduccao}.

Conforme \citeonline{tan2009introduccao} a avaliação do desempenho de um modelo
de classificação é baseada na contagem de registros do conjunto de teste que
foram classificados correta e incorretamente. Estas contagens são organizadas em
uma tabela denominada matriz de confusão. O Quadro \ref{confusionMatrix}
apresenta uma matriz de confusão para um problema de classificação binária. A
partir das entradas da matriz de confusão, o número de previsões corretas
realizadas pelo modelo é \((f_{11} + f_{00})\) e o número de previsões
incorretas é \((f_{10} + f_{01})\).

\begin{quadro}[]
  \centering
  \caption{Exemplo de matriz de confusão}
  \label{confusionMatrix}
  \begin{tabular}{ll|c|c|}
    \cline{3-4}
    \multicolumn{1}{c}{\textbf{}} & \multicolumn{1}{c|}{\textbf{}} & \multicolumn{2}{l|}{\textbf{Classe prevista}} \\ \cline{3-4}
    & \multicolumn{1}{c|}{\textbf{}} & Classe = 1 & Classe = 0 \\ \hline
    \multicolumn{1}{|l|}{\multirow{2}{*}{\textbf{Classe real}}} & Classe = 1 & $f_{11}$ & $f_{10}$ \\ \cline{2-4}
    \multicolumn{1}{|l|}{} & Classe = 0 & $f_{01}$ & $f_{00}$ \\ \hline
  \end{tabular}
  \Ididthis
\end{quadro}

A matriz de confusão mostra informações importantes para determinar o desempenho
do modelo, no entanto, resumir essas informações em um único número é mais
conveniente quando queremos comparar o desempenho entre  diferentes modelos.
Isso pode ser feito usando uma métrica de desempenho como a precisão, que é
definida da seguinte maneira \cite{tan2009introduccao}:
\[
  \text{Precisão} =
  \frac
    {\text{Número de previsões corretas}}
    {\text{Número total de previsões}} =
  \frac
    {f_{11} + f_{00}}
    {f_{11} + f_{10} + f_{01} + f_{00}}
\]

\subsubsection{Árvore de decisão}

Em ML, existem dois tipos de árvores de decisão: árvores de regressão e árvores
de classificação. Uma árvore de decisão utiliza uma abordagem baseada em regras
para dividir o domínio dos dados em múltiplos espaços lineares e prever
respostas. Se as respostas previstas forem contínuas, então a árvore de decisão
é chamada de árvore de regressão, e se as previsões são discretas, ou seja,
pertencem a uma classe, então a árvore de decisão é chamada de árvore de
classificação \cite{suthaharan2016machine}.

De acordo com \citeonline{suthaharan2016machine}, árvores de decisão são modelos
de aprendizado supervisionado, que mapeiam o domínio dos dados hierarquicamente
em um conjunto de respostas. Dividindo o domínio dos dados (também chamado de
nó), recursivamente, em dois subdomínios, de forma que os subdomínios tenham um
maior ganho de informação que o nó que foi dividido. Já que o objetivo do
aprendizado supervisionado é a classificação dos dados, portanto,  o aumento do
ganho de informação influencia na eficiência da classificação nos subdomínios
criados pela divisão. Encontrar a divisão que traga o máximo de ganho de
informação, ou seja, eficiência na classificação é o objetivo do dos algoritmos
de otimização no aprendizado supervisionado baseado em árvores de decisão. Na
Figura \ref{decisionTree} vemos um exemplo de árvore de decisão em termos de
divisão de domínios focado no ganho de informação.

\imagem{.60}{decision_tree}{\label{decisionTree}Exemplo de árvore de decisão usada para classificação construída com um domínio de dados uni-dimensional}{\citeonline{suthaharan2016machine}}

\citeonline{suthaharan2016machine} traz um exemplo de classificação usando
árvore de decisão. Suponha que temos um sistema que produz eventos (observações)
que podem pertencer a uma de duas classes, \(0\) ou \(1\), e estes eventos
dependem apenas de uma variável. Consequentemente, definimos o domínio como: \(D
= \{e_1, e_2, \ldots, e_n\}\) (assumimos que isto é um conjunto ordenado), e
seus rótulos de classe correspondentes \(L = {r_1, r_2, r_3, \ldots, r_n}\),
onde \(r_i\) pertence \(\{0, 1\}\), e \(i = 1 \ldots n\). A propagação dos
rótulos das classes sobre o domínio dos dados determina a facilidade na
classificação. Representamos o ganho de informação do domínio \(D\) em relação a
\(L\) por \(I_i\) e dividimos o conjunto ordenado na localização \(m\) para
formar dois subdomínios \(D_1 = \{e_1, e_2, \ldots, e_m\}\) e \(D_2 = \{e_{m+1},
e_{m+2}, \ldots, e_n\}\) com os conjuntos de respostas correspondentes \(L_1 =
\{r_1, r_2, \ldots, r_m\}\) e \(L_2 = \{r_{m+1}, r_{m+2}, \ldots, r_n\}\). Se os
respectivos ganhos de informação são \(I_{i1}\) e \(I_{i2}\), então \(m\) será
considerado a melhor divisão se a  \(\text{média}(I_{i1}, I_{i2}) > I_i\). Não
obstante, precisamos de uma boa medida quantitativa para mensurar o ganho de
informação obtido após a divisão dos dados.

Vamos supor que \(p_0\) e \(p_1\) representem as probabilidades de que as
classes \(0\) e \(1\) possam ser extraídas do domínio \(D\), respectivamente.
Se, por exemplo, \(|p_0 - p_1| \to 1\); então podemos observar que uma classe em
particular tem grande predominância neste domínio, portanto, não é mais
necessário dividir os dados. Similarmente, se \(|p_0 - p_1| \to 0\), então as
classes tem predominância igual no domínio; logo, uma divisão é necessária.
Neste caso geramos dois subdomínios \(D_1\) e \(D_2\). Digamos que, \(q_0\) e
\(q_1\) são as probabilidades de que a classe \(0\) e a classe \(1\) sejam
derivadas do subdomínio \(D_1\), respectivamente. Se a divisão for eficiente,
\(q_0 > p_0\) ou \(q_1 > p_1\). Assumindo \(q_0 > p_0\), então \(q_0 = p_0 +
\epsilon\), onde \(\epsilon > 0\).
\[|q_0 - q_1| = |2q_0 - 1| = |2(p_0 + \epsilon) - 1| = |2p_0 + 2\epsilon - 1|\]
\[|q_0 - q_1| = |p_0 + 1 - p_1 + 2\epsilon - 1| = |p_0 - p_1 + 2\epsilon|\]
Esta equação enfatiza a seguinte inequação, (quando \(q_0 > p_0)\):
\[|q_0 - q_1| > |p_0 - p_1|\]

As diferenças absolutas na inequação acima são as medidas quantitativas de
proporcionalidade entre as classes em seus respectivos subdomínios. Essas medida
probabilística é uma boa métrica para abordagem de otimização de árvores de
decisão.

\subsubsection{K-ésimo vizinho mais próximo}

\citeonline{fix1951discriminatory} introduziram um método não paramétrico de
reconhecimento de padrões que ficou conhecido como Regra do K-ésimo Vizinho Mais
Próximo (KNN, do inglês, \textit{K-nearest-neighbor}). O KNN é um dos algoritmos
de classificação mais simples e mais fundamentais e deveria ser a primeira
escolha para um estudo de classificação quando se tem pouco ou nenhum
conhecimento sobre a distribuição dos dados. A classificação com KNN foi
desenvolvida a partir da necessidade de realizar análises discriminatórias
quando estimativas confiáveis de densidade de probabilidade dos dados não são
conhecidas ou difíceis de determinar.

\citeonline{cover1967nearest} descreveram as propriedades formais do KNN, por
exemplo, foi demonstrado que para \(k = 1\) e \(n \to \infty\) o erro de
classificação do KNN é limitado pelo dobro da taxa de erro de Bayes. Desde que
essas propriedades formais foram estabelecidas, seguiu-se uma longa linha de
investigações, incluindo uma abordagem de rejeição, melhoramento em relação com
a taxa de erro de Bayes, abordagem com pesos nas distâncias
\cite{peterson2009knn}.

Segundo \citeonline{tan2009introduccao} um classificador que utiliza KNN
representa cada exemplo, de treinamento ou de teste, como um ponto de dado em um
espaço \(d\)-dimensional, onde \(d\) é a quantidade de atributos. Dado um
exemplo de teste, calcula-se a sua proximidade com o resto dos pontos de dados
do conjunto de treinamento, usando alguma medida de distância, geralmente a
distância euclidiana. Os \(k\) vizinhos mais próximos de um determinado ponto de
teste \(z\) se referem aos \(k\) pontos com menor distância de \(z\). Então,
\(z\) é classificado com base nos rótulos de classe do seus vizinhos mais
próximos e lhe é atribuída a classe majoritária dos seus vizinhos mais próximos.
No exemplo da Figura \ref{knn}, no qual o símbolo \(\textbf{-}\)
representa a classe negativo, o símbolo \(\textbf{+}\) representa a classe
positivo e \(\lambda\) representa um ponto dado a ser classificado. Na Figura
\ref{knnA}, onde \(k = 1\), foi atribuído ao ponto dado a classe negativo. Na
Figura \ref{knnB}, com \(k = 2\), os dois vizinhos mais próximos do ponto dado
tem classes distintas, portanto, podemos atribuir aleatoriamente qualquer uma
das duas classes. Na Figura \ref{knnC}, com \(k = 3\), dois dos vizinhos mais
próximos do ponto dado são da classe positivo e apenas um é da classe negativo,
logo, atribuímos ao ponto dado a classe positivo.

\begin{figure}[!htb]
  \centering
  \caption{\label{knn} Os 1, 2 e 3 vizinhos mais próximos de um ponto dado}
  \subcaptionbox{\label{knnA}1-vizinho mais próximo}{\includegraphics[scale=.75]{img/knn_example_a}}\qquad
  \subcaptionbox{\label{knnB}2-vizinhos mais próximo}{\includegraphics[scale=.75]{img/knn_example_b}}\qquad
  \subcaptionbox{\label{knnC}3-vizinhos mais próximo}{\includegraphics[scale=.75]{img/knn_example_c}}
  \vspace{1.5em}
  \Otherguydidthis{tan2009introduccao}
\end{figure}

O desempenho de um classificador usando KNN pode ser melhorado quando os
atributos são transformados antes da análise de classificação. A forma mais
comum de transformação é a normalização ou padronização. A normalização remove
efeitos provocados por atributos com escalas diferentes, como, o atributo peso
de um paciente que pode ser baseado na unidade quilograma enquanto os valores de
proteína no sangue são baseados em nanograma por decilitro variando entre \(-3\)
e \(3\), logo, o peso do paciente teria maior influência no cálculo das
distâncias entre os pontos de exemplo e, por consequência, na classificação
\cite{peterson2009knn}.

\subsubsection{Regressão logística}

A Regressão Logística (RL) é uma generalização da regressão linear. É usada,
principalmente, para prever variáveis dependentes binárias ou de múltiplas
classes. Como a variável de resposta é discreta, ela não pode ser modelada
diretamente por regressão linear. Portanto, em vez de prever uma estimativa de
ponto do evento em si, o modelo baseia-se para prever a probabilidade de sua
ocorrência \cite{csen2012predicting}.

O modelo de RL surge do desejo de modelar as probabilidades posteriores de \(K\)
classes através de funções lineares em \(x\), ao mesmo tempo, garantir que a
soma dessas probabilidades seja um (1) e elas permaneçam no intervalo entre
\(0\) e \(1\) \cite{james2013introduction}.

Uma vantagem da RL no processo de classificação de uma variável dependente
binária (binomial), é que, nela, pode ser usado um conjunto de variáveis
independentes numéricas ou categóricas \cite{kleinbaum2002analysis}.

Dada uma variável ou conjunto de variáveis \(X\), podemos utilizar um modelo de
RL para calcular a probabilidade de pertencimento à classe \(y\). Para cada
valor ou valores de \(X\) pode ser feita uma previsão para a classe \(y\). Por
exemplo, pode-se dizer que o item sendo testado pertence a classe \(y\) sempre
que o modelo RL retornar uma probabilidade maior que 50\%, sendo que este limiar
pode ser ajustado de acordo com a necessidade do problema abordado
\cite{james2013introduction}.

Os modelos de RL para diversas variáveis é descrito pela seguinte fórmula:
\[\text{logit}(p_i)
= \text{ln}\left(\frac{p_i}{1 - p_i}\right)
= \beta_0 + \beta_1 X_{1,i} + \ldots + \beta_k X_{k,i}\]

Onde, \(\beta_0\), \(\beta_1\), \ldots, \(\beta_k\) são os coeficientes das
variáveis que explicam a ocorrência de determinado evento e \(p_i\) é a
probabilidade de um evento ocorrer dado o conjunto de variáveis \(i\).

O resultado do modelo \textit{logit} é uma curva em forma de S (Figura
\ref{logisticRegression}).  Para estimar um modelo de regressão logística, essa
curva de valores previstos é ajustada aos dados reais, analogamente, como é
feito com uma relação linear em regressão múltipla.

\imagem{.5}{logistic_regression}{\label{logisticRegression}Previsões utilizando
regressão logística. As probabilidades se encontram no intervalo entre 0 e
1}{\citeonline{james2013introduction}}

Em níveis muito baixos da variável independente, a probabilidade se aproxima de
0\%, mas nunca alcança tal valor. Da mesma forma, quando o valor da variável
independente aumenta, os valores previstos crescem para acima da curva, mas, em
seguida, a inclinação começa a diminuir, aproximando a probabilidade de 100\%,
sem, entretanto, exceder esse valor \cite{hair2009analise}.

\section{Trabalhos relacionados}

\citeonline{ramos2016mapeamento}, propuseram o mapeamento do comportamento de
usuários de um \textit{Learning Management System} (LMS), em variáveis que
representam os contrutos da TDT. O objetivo foi descrever e validar um conjunto
de variáveis com as quais esses construtos podem ser medidos, permitindo o
desenvolvimento de pesquisas na área, assim como a obtenção destas medidas a
qualquer momento do curso e sem a necessidade de questionários. A criação e
validação de um conjunto final de variáveis foi feita a partir da Análise
Fatorial Confirmatória (CFA), que apontou como cada construto pode ser
representado por um conjunto de atributos obtidos a partir do banco de dados do
LMS.

\citeonline{ramos2018estudo}, analisaram a performance de diferentes algoritmos
na previsão da evasão em alunos EAD. No trabalho foram utilizados dados de
turmas de dois cursos de graduação na Universidade de Pernambuco (UPE). Os
algoritmos testados foram: Árvore de Decisão, Máquina de Vetor de Suporte (SVM),
Rede Neural Artificial, K-Vizinhos Mais Próximos (KNN) e Regressão Logística. As
variáveis foram construídas com base na TDT. O algoritmo com maior acurácia foi
o KNN, com maior precisão foi o SVM e a Regressão Logística teve os maiores
valores de Recall e Área Sob a Curva ROC (AUC).

\citeonline{queiroga2018modelo}, elaboraram um modelo de predição da evasão de
estudantes em cursos técnicos a distância, por meio de mineração de dados,
utilizando dados de turmas EAD do Instituto
Federal Sul-rio-grandense. Os algoritmos utilizados para gerar os
modelos testados foram: \textit{Bayes Net}, \textit{Simple Logistic},
\textit{Multilayer Perceptron}, \textit{Random Forest} e J48, implementados na
biblioteca WEKA. Todos os algoritmos selecionados previram com exatidão de 95\%
a evasão de um aluno antes do final do primeiro ano. O algoritmo que mais se
destacou no quesito acurácia foi o Random Forest, com 85\%.

\citeonline{manhaes2011previsao}, utilizaram mineração de dados para identificar
antecipadamente alunos com risco de evasão. Foram utilizados dados de cursos de
graduação da Universidade Federal do Rio de Janeiro (UFRJ). Os resultados
mostraram que utilizando as primeiras notas semestrais dos calouros é possível
identificar com precisão de 80\% a situação final do aluno no curso.

\citeonline{paz2017identificando}, alicaram KDD em dados coletados em uma
instituição de esnino superior (IES), e, através da tarefa de classificação,
utilizando a técnica de árvores de decisão, atingiram acurácia de 90\% na
identificação de alunos evasores.

\citeonline{ramos2016abordagem} desenvolveu e testou modelos preditivos com base
nos algoritmos Árvore de Decisão, SVM, Rede Neural Artificial, KNN e Regressão
Logística, usando com base as variáveis representativas dos construtos da
distância transacional, obtidas em trabalho anterior \cite{ramos2016mapeamento}.
Esse trabalho serviu como principal referência para o desenvolvimento deste
estudo, a fim de verificar a aplicabilidade do método em um outro cenário
educacional.

\section{Considerações finais}

Neste capítulo foram apresentados os principais conceitos da EAD, dados
demográficos sobre a evasão, os métodos e algoritmos de ML que foram utilizados
neste trabalho, e os trabalhos relacionados na literatura.

No próximo capítulo é detalhado o método KDD e como foi aplicado neste estudo.
